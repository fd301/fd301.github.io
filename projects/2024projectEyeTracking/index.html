
<!DOCTYPE html>
<html>
<head>
<APM_DO_NOT_TOUCH>

<script type="text/javascript">
(function(){
window.TXOV=!!window.TXOV;try{(function(){(function(){var a={decrypt:function(d){try{return JSON.parse(function(g){g=g.split("l");var h="";for(var k=0;k<g.length;++k)h+=String.fromCharCode(g[k]);return h}(d))}catch(g){}}};return a={configuration:a.decrypt("123l34l97l99l116l105l118l101l34l58l34l110l111l34l44l34l100l101l98l117l103l103l105l110l103l34l58l34l110l111l34l44l34l109l111l100l117l108l101l49l34l58l34l101l110l97l98l108l101l100l34l44l34l109l111l100l117l108l101l50l34l58l34l101l110l97l98l108l101l100l34l44l34l109l111l100l117l108l101l51l34l58l34l101l110l97l98l108l101l100l34l44l34l109l111l100l117l108l101l52l34l58l34l101l110l97l98l108l101l100l34l125")}})();
var b=37;try{var aa,da,ma=c(759)?0:1,oa=c(293)?1:0,qa=c(742)?0:1;for(var ra=(c(840),0);ra<da;++ra)ma+=c(241)?2:1,oa+=(c(93),2),qa+=(c(514),3);aa=ma+oa+qa;window.Qa===aa&&(window.Qa=++aa)}catch(a){window.Qa=aa}var e=!0;function ua(a){var d=31;a&&(document[f(d,149,136,146,136,129,136,139,136,147,152,114,147,128,147,132)]&&document[q(d,149,136,146,136,129,136,139,136,147,152,114,147,128,147,132)]!==t(68616527635,d)||(e=!1));return e}function t(a,d){a+=d;return a.toString(36)}function ya(){}
ua(window[ya[t(1086817,b)]]===ya);ua(typeof ie9rgb4!==q(b,139,154,147,136,153,142,148,147));ua(RegExp("\x3c")[t(1372168,b)](function(){return"\x3c"})&!RegExp(t(42852,b))[t(1372168,b)](function(){return"'x3'+'d';"}));
var za=window[f(b,134,153,153,134,136,141,106,155,138,147,153)]||RegExp(q(b,146,148,135,142,161,134,147,137,151,148,142,137),t(-19,b))[t(1372168,b)](window["\x6e\x61vi\x67a\x74\x6f\x72"]["\x75\x73e\x72A\x67\x65\x6et"]),Ca=+new Date+(c(532)?6E5:742855),Da,Ea,Ha,Ia=window[f(b,152,138,153,121,142,146,138,148,154,153)],Ja=za?c(45)?3E4:38389:c(895)?8972:6E3;
document[q(b,134,137,137,106,155,138,147,153,113,142,152,153,138,147,138,151)]&&document[f(b,134,137,137,106,155,138,147,153,113,142,152,153,138,147,138,151)](f(b,155,142,152,142,135,142,145,142,153,158,136,141,134,147,140,138),function(a){var d=50;document[q(d,168,155,165,155,148,155,158,155,166,171,133,166,147,166,151)]&&(document[q(d,168,155,165,155,148,155,158,155,166,171,133,166,147,166,151)]===f(d,154,155,150,150,151,160)&&a[f(d,155,165,134,164,167,165,166,151,150)]?Ha=!0:document[q(d,168,155,
165,155,148,155,158,155,166,171,133,166,147,166,151)]===q(d,168,155,165,155,148,158,151)&&(Da=+new Date,Ha=!1,w()))});function f(a){var d=arguments.length,g=[];for(var h=1;h<d;++h)g.push(arguments[h]-a);return String.fromCharCode.apply(String,g)}function w(){if(!document[q(79,192,196,180,193,200,162,180,187,180,178,195,190,193)])return!0;var a=+new Date;if(a>Ca&&(c(853)?544803:6E5)>a-Da)return ua(!1);var d=ua(Ea&&!Ha&&Da+Ja<a);Da=a;Ea||(Ea=!0,Ia(function(){Ea=!1},c(669)?0:1));return d}w();
var Ka=[c(349)?17795081:26240080,c(524)?27611931586:2147483647,c(31)?1558153217:1574108404];function La(a){var d=41;a=typeof a===q(d,156,157,155,146,151,144)?a:a[q(d,157,152,124,157,155,146,151,144)](c(231)?36:26);var g=window[a];if(!g||!g[f(d,157,152,124,157,155,146,151,144)])return;var h=""+g;window[a]=function(k,l){Ea=!1;return g(k,l)};window[a][q(d,157,152,124,157,155,146,151,144)]=function(){return h}}for(var Na=(c(446),0);Na<Ka[q(b,145,138,147,140,153,141)];++Na)La(Ka[Na]);
ua(!1!==window[q(b,121,125,116,123)]);window.Ga=window.Ga||{};window.Ga.Wb="089a67c1f41940000dac06f42265bafadcd72aa039a617b903477c91089fe3c5126e257ffeb960b0e61ab054de65811634a11f1b80c1911b4e4d7b84a72f0490ea4ae8845b1c57d9";function q(a){var d=arguments.length,g=[];for(var h=1;h<d;h++)g[h-1]=arguments[h]-a;return String.fromCharCode.apply(String,g)}function B(a){var d=+new Date;if(!document[f(69,182,186,170,183,190,152,170,177,170,168,185,180,183,134,177,177)]||d>Ca&&(c(984)?342371:6E5)>d-Da)var g=ua(!1);else g=ua(Ea&&!Ha&&Da+Ja<d),Da=d,Ea||(Ea=!0,Ia(function(){Ea=!1},c(682)?0:1));return!(arguments[a]^g)}
function c(a){return 653>a}(function Pa(a){a&&"number"!==typeof a||("number"!==typeof a&&(a=1E3),a=Math.max(a,1),setInterval(function(){Pa(a-10)},a))})(!0);})();}catch(x){}finally{ie9rgb4=void(0);};function ie9rgb4(a,b){return a>>b>>0};

})();

</script>
</APM_DO_NOT_TOUCH>

<script type="text/javascript" src="/TSPD/082149a1b4ab2000a359e9001bdabfe5af011fea5a315b766c2459ecbfe2bb56b1851903e34e931f?type=9"></script>

  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="We uncover a vulnerability in LoRA fine-tuned models wherein an attacker is able to undo the fine-tuning process and recover the weights of the original pre-trained model.">
  <meta property="og:title" content="Recovering the Pre-Fine-Tuning Weights of Generative Models"/>
  <meta property="og:description" content="We uncover a vulnerability in LoRA fine-tuned models wherein an attacker is able to undo the fine-tuning process and recover the weights of the original pre-trained model."/>
  <meta property="og:url" content="https://vision.huji.ac.il/spectral_detuning/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/og_banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Recovering the Pre-Fine-Tuning Weights of Generative Models">
  <meta name="twitter:description" content="We uncover a vulnerability in LoRA fine-tuned models wherein an attacker is able to undo the fine-tuning process and recover the weights of the original pre-trained model.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="LLMs, Model Alignment, Stable Diffusion, Pre-Fine-Tuning, Spectral DeTuning, Mistral, LLaMA, jailbreaking, safety training, fine-tuning">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ML & VR</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="static/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/images/favicon-16x16.png">
  <link rel="manifest" href="static/images/site.webmanifest">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ML-Driven Cognitive Workload Estimation in a VR-based Sustained Attention Task</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://fd301.github.io/team.html" target="_blank">Dominik Szczepaniak</a>,</span>
                <span class="author-block">
                  <a href="https://www.gla.ac.uk/schools/psychologyneuroscience/staff/monikaharvey/" target="_blank">Monika Harvey</a>,</span>
                <span class="author-block">
                  <a href="http://fdeligianni.site/" target="_blank">Fani Deligianni</a>,</span>
                  </span>
                </div>

                <div class="is-size-5 publication-authors">
                  <span class="author-block">Social AI CDT, Bio-AIm Lab, School of Computing Science, School of Psychology<br>University of Glasgow<br>ISMAR 2024</span>
                </div>

                <div class="column has-text-centered">
                  <div class="publication-links">


                   <!-- Arxiv PDF link -->
                   <span class="link-block">
                    <a href="https://eprints.gla.ac.uk/331792/" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>


                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> --> 
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>







<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p> Cognitive training can boost and sharpen the brain’s abilities to remember, focus, 
            and switch between different tasks. One of the key elements of cognitive training is 
            that it manipulates 'cognitive load', by adjusting the intensity of the intervention 
            to suit the participant’s ability level and keep the session enjoyable. This study 
            introduces a novel sustained attention task in Virtual Reality (VR) to predict cognitive load dynamically. 
            Unlike previous research, which often used non-VR settings, simpler tasks, or performance metrics as 
            predictors, our approach aims to measure cognitive load objectively in a more ecologically valid and 
            gamified VR environment. We employed machine learning techniques to enable real-time, personalized cognitive training. 
            This work contributes to the development of more effective cognitive training interventions that can adapt to 
            individual differences and maintain optimal engagement levels.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <p>
             The main contributions of our work are as follows:
             <ol>
              <li>Introducing sustained attention training into a Virtual Reality environment while collecting eye-tracking and physiological data.</li>
              <li>Designing an ecologically valid task that does not require specialist equipment and can be used at home by the users. </li>
              <li>Training classifiers to identify both objective difficulty changes as well as perceived cognitive load as experienced by participants.</li>
            </ol>
            </p>
        
      </div>
    </div>
  </div>
</div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/capacity.png" alt="Capacity versus Selectivity flowchart"/>
        <h2 class="subtitle has-text-centered">
          High level overview of the relationship between attentional capacity and selectivity. The balance between both is key to designing effective and engaging interventions targetting attention.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/ingame.png" alt="in-game view of the task"/>
        <h2 class="subtitle has-text-centered">
          In-game view of progressively increasing difficulties.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/objective.png" alt="MY ALT TEXT"/>
        <h2 class="pie charts showing the relationship between objective and subjective difficulty">
          The frequencies of perceived difficulties mapped over objective difficulties (objective difficulty is balanced for each participant).
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/within.png" alt="barcharts of accuracies within participants"/>
      <h2 class="subtitle has-text-centered">
        Model performance for different validation protocols comparing objective and perceived difficulty predictions using different combinations of data types 
        (Within Subject Cross-Validation Protocol (same participants seen during testing and training)).
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/across.png" alt="barcharts of accuracies across participants"/>
      <h2 class="subtitle has-text-centered">
        Model performance for different validation protocols comparing objective and perceived difficulty predictions using different combinations of data types 
        (Across Subject Cross-Validation Protocol (participants left out during training and seen only during validation and testing)).
      </h2>
    </div>
    <div class="item">
      <!-- Your image here -->
      <img src="static/images/roc.png" alt="ROC curves"/>
      <h2 class="subtitle has-text-centered">
        Receiver Operating Characteristic Curves for objective difficulty (left) and perceived difficulty (right) prediction using SVM (eye-tracking data only).
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


  <!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/poster_ismar_24_updated_3 (1).pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->





<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{Dominik2024,
  title={ML-Driven Cognitive Workload Estimation in a VR-based Sustained Attention Task},
  author={Szczepaniak, Dominik and Harvey, Monika and Deligianni, Fani},
  journal={IEEE International Symposium on Mixed and Augmented Reality},
  year={2024}
}</code></pre>
  </div>
</section> 
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theֲ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>ֲ project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- Default Statcounter code for Spectral DeTuning
https://vision.huji.ac.il/spectral_detuning/ -->
<script type="text/javascript">
var sc_project=12968013; 
var sc_invisible=1; 
var sc_security="c534194a"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - Statcounter" href="https://statcounter.com/"
target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12968013/0/c534194a/1/"
alt="Web Analytics Made Easy - Statcounter"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

</body>
</html>