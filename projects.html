<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="BioAIm, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="icon" href="./images/BioAIm_banner.jpg">
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title></title> --->
<title>BioAIm</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="layout-content"> <!-- nomenu  -->
<div id="banner-container">
<img src="./images/banner_main.png" alt="logo pic" />
<div id="menu-overlay">
<a href="index.html">About</a>
<a href="projects.html">Projects</a>
<a href="team.html">Team</a>
<a href="teaching.html">Teaching</a>
<a href="vacancies.html">Vacancies</a>
<a href="publications_All.html">Publications</a>
</div>
</div>
<h1>Projects - Selected Publications</h1>
<h2>Human Motion Analysis and Privacy Preservation </h2>
<table class="imgtable"><tr><td>
<img src="./images/projects/2024_HPE_KnowledgeDistil_Kaushik.png" alt="" width="240px" />&nbsp;</td>
<td align="left"><h2>Efficient Human Pose Estimation</h2>
<h3>Knowledge Distillation with Global Filters for Efficient Human Pose Estimation</h3>
<p>K.B. Sivangi and F. Deligianni
BMVC 2024
<a href="https://eprints.gla.ac.uk/330515/" target=&ldquo;blank&rdquo;>pdf</a>, <a href="https://bhairava2898.github.io/kdgflhpe/" target=&ldquo;blank&rdquo;>Project Page and Source Code</a>
</p>
<p>By distilling knowledge from the teacher model, the student network learns to predict keypoints with high accuracy while maintaining lower computational complexity. 
This approach significantly advances the field by balancing efficiency and accuracy.  
We specifically employ Global Filter Layers, which operate in the frequency domain, to reduce the processing overhead associated with traditional attention mechanisms.
Our method was evaluated using both static and dynamic filter weighting strategies, demonstrating that the Global Filter Layers not only improve speed but also maintain a competitive level of accuracy compared to traditional attention-based models. 
<a href="https://bhairava2898.github.io/kdgflhpe/" target=&ldquo;blank&rdquo;>&hellip;read more</a>
</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="./images/projects/2024_radarImg_IZ.jpg" alt="" width="280px" />&nbsp;</td>
<td align="left"><h2>Privacy-Preservation in Radar-based HAR</h2>
<h3>Differentially Private Integrated Decision Gradients (IDG-DP) for Radar-based Human Activity Recognition </h3>
<p>I. Zakariyya, L. Tran, K.B. Sivangi, F. Deligianni, WACV 2025, accepted. <a href="https://eprints.gla.ac.uk/340661/" target=&ldquo;blank&rdquo;>pdf</a>
</p>
<p>The advent of radar-based sensing systems has captured the spotlight for they are able to operate without physical contact and they can integrate with pre-existing Wi-Fi networks. They are also seen as less privacy-invasive compared to camera-based systems. However, recent research has shown high accuracy in recognizing subjects or gender from radar gait patterns, raising privacy concerns. This study addresses these issues by investigating privacy vulnerabilities in radar-based Human Activity Recognition (HAR) systems and proposing a novel method for privacy preservation using Differential Privacy (DP) driven by attributions derived with Integrated Decision Gradient (IDG) algorithm. 
</p>
</td></tr></table>
<h2>Medical Image Analysis</h2>
<table class="imgtable"><tr><td>
<img src="./images/projects/2024_Registration_SSL_QL.jpg" alt="" width="250px" />&nbsp;</td>
<td align="left"><h2>Semi-Supervised Medical Image Segmentation</h2>
<h3>Learning Semi-Supervised Medical Image Segmentation from Spatial Registration</h3>
<p>Q. Liu, P. Henderson, X. Gu, H. Dai, WACV 2025, accepted. <a href="https://arxiv.org/abs/2409.10422" target=&ldquo;blank&rdquo;>pdf</a>
</p>
<p>We are the first to propose a registration-guided method for semi-supervised medical image segmentation, by integrating registration with a contrastive
cross-teaching framework. Furthermore, we introduce a novel registration supervision loss that enhances cross-teaching, by providing additional and
informative registered pseudo-labels early in training, automatically selecting the best registered volumes.<a href="Read" target=&ldquo;blank&rdquo;>more</a>
</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="./images/projects/2023_Franscesco_VQA.png" alt="" width="280px" />&nbsp;</td>
<td align="left"><h2>Vision-Language Models for Chest X-Ray Radiology</h2>
<h3>Controllable Chest X-Ray Report Generation from Longitudinal Representations</h3>
<p>Q. Dalla Serra, C. Wang, F. Deligianni, J. Dalton, and A. Q. O'Neil, EMNLP 2023.
<a href="https://arxiv.org/abs/2310.05881" target=&ldquo;blank&rdquo;>WACV2025_arxiv</a>, <a href="https://fds-uog.github.io/controllable_emnlp23.github.io/" target=&ldquo;blank&rdquo;>Project Page</a>
</p>
<p>Radiology reporting is a time-consuming process, and scan results are often subject to delays. To enhance the accuracy and interpretability of current vision-language models for Chest X-Ray Radiology we
leverage an existing visual input format of anatomical tokens. We introduce two novel aspects: (1) longitudinal representation learning – we input the prior scan as an additional input, proposing a method to align, concatenate and fuse the current and prior visual information into a joint longitudinal representation which can be provided to the multimodal report generation model; (2) sentence-anatomy dropout – a training strategy for controllability in which the report generator model is trained to predict only sentences from the original report which correspond to the subset of anatomical regions given as input.
</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="./images/projects/BraTS2019_certaintyGuided.jpg" alt="" width="280px" />&nbsp;</td>
<td align="left"><h2>Semi-Supervised Medical Image Segmentation</h2>
<h3>Certainty-Guided Cross Contrastive Learning for Semi-Supervised Medical Image Segmentation</h3>
<p>Q. Liu, X. Gu, P. Henderson, BMVC 2023.
<a href="https://arxiv.org/abs/2306.14293" target=&ldquo;blank&rdquo;>BMVC2023_arxiv</a>, <a href="https://kathyliu579.github.io/project_describ/" target=&ldquo;blank&rdquo;>Project Page and Source Code</a>, <a href="https://www.techrxiv.org/users/815474/articles/1216359-certainty-guided-cross-contrastive-learning-for-semi-supervised-medical-image-segmentation" target=&ldquo;blank&rdquo;>Extended Version</a>
</p>
<p>We develop a novel Multi-Scale Cross Supervised Contrastive Learning (MCSC) framework, to segment structures in medical images. We jointly train CNN and Transformer models, regularising their features to be semantically consistent across different scales. 
To tackle class imbalance, we take into account the prevalence of each class to guide contrastive learning and ensure that features adequately capture infrequent classes.
</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="./images/projects/2023_ICASSP_segmentation_results.jpg" alt="" width="280px" />&nbsp;</td>
<td align="left"><h2>Fully Supervised Medical Image Segmentation</h2>
<h3>Optimizing Vision Transformers for Medical Image Segmentation</h3>
<p>Q. Liu, C. Kaul, J. Wang, C. Anagnostopoulos, R. Murray-Smith, F. Deligianni, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2023.
<a href="https://ieeexplore.ieee.org/document/10096379" target=&ldquo;blank&rdquo;>paper</a>
</p>
<p>We design of a compact and accurate Transformer network for Medical Image Semantic Segmentation, which introduces convolutions in a multi-stage design for hierarchically enhancing spatial and local modeling ability of Transformers. This is mainly achieved by our well-designed Convolutional Swin Transformer (CST) block which merges convolutions with Multi-Head Self-Attention and Feed-Forward Networks for providing inherent localized spatial context and inductive biases.
</p>
</td></tr></table>
<h2>Analysis of Neurophysiological Signals</h2>
<table class="imgtable"><tr><td>
<img src="./images/projects/2024_DominikEyeTracking.png" alt="" width="280px" />&nbsp;</td>
<td align="left"><h2>Building Machine Learning Models to Detect Cognitive Workload </h2>
<h3>ML-Driven Cognitive Workload Estimation in a VR-based Sustained Attention Task</h3>
<p>D. Szczepaniak, M. Harvey, F. Deligianni, 
IEEE International Symposium on Mixed and Augmented Reality, 2024.
<a href="https://eprints.gla.ac.uk/331792/" target=&ldquo;blank&rdquo;>paper</a>, <a href="./projects/2024projectEyeTracking/index.html" target=&ldquo;blank&rdquo;>Project Page</a>
</p>
<p>We employed machine learning techniques to enable real-time, personalized cognitive training. This work contributes to the development of more effective cognitive training interventions that can adapt to individual differences and maintain optimal engagement levels.
</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="./images/projects/2024_musicGait_ACII_small.jpg" alt="" width="280px" />&nbsp;</td>
<td align="left"><h2>Computational Interfaces for Personalised Music-Therapy</h2>
<h3>Fusion of Spatial and Riemannian Features to Enhance Detection of Gait Adaptation Mental States During Rhythmic Auditory Stimulation</h3>
<p>N. Lai-Tan, M. Philiastides, F. Deligianni, 
International Conference on Affective Computing and Intelligent Interaction (ACII 2024), Best Student Paper Runner-up Award, 2024.
<a href="https://eprints.gla.ac.uk/328351/" target=&ldquo;blank&rdquo;>paper</a>
</p>
<p>Fusion of Spatial and Riemannian Features to Enhance Detection of Gait Adaptation Mental States During Rhythmic Auditory Stimulation&nbsp;&nbsp;&nbsp;
</p>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="./images/projects/2024_ECG_ISBI_MA.jpg" alt="" width="280px" />&nbsp;</td>
<td align="left"><h2>12-Lead ECG Classification in Congenital Heart Disease</h2>
<h3>Riemannian Prediction of Anatomical Diagnoses in Congenital Heart Disease based on 12-lead ECG's</h3>
<p>M. Alkan, G. Veldtman, F. Deligianni, IEEE International Symposium on Biomedical Imaging (IEEE ISBI), 2024 
<a href="https://arxiv.org/abs/2312.09437" target=&ldquo;blank&rdquo;>arxiv</a>, <a href="https://ieeexplore.ieee.org/document/10635164" target=&ldquo;blank&rdquo;>paper</a>, <a href="https://github.com/alkanmuhammet/ISBI" target=&ldquo;blank&rdquo;>code</a>
</p>
<p>Here, we exploit the Riemannian geometry of the spatial covariance structure of the ECG signal to improve classification in extremely heterogeneous and small datasets.
</p>
</td></tr></table>
</div> <!-- <div id="layout-content"> -->
<div id="footer-container">
<div id="footer">
<div id="footer-text">
Last edited  on 2024-11-05 00:19:30 GMT. </br>
Powered by <a href="https://github.com/szl2/jemdoc-new-design" target="blank">jemdoc + new design</a>.
</div> <!-- <div id="footer-text"> -->
</div> <!-- <div id="footer"> -->
</div> <!-- <div id="footer-container"> -->
<div> <!-- nomenulastbit to counteract  <div id="layout">  -->
</div> <!--- <div id="layout"> --->
</div> <!--- <div id="main-container"> --->
<script>
function openNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "280px";
        document.getElementById("layout-content-container").style.marginLeft = "280.8px";
        document.getElementById("layout-content-container").style.position = "fixed";
    }
}
function closeNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "0";
        document.getElementById("layout-content-container").style.position = "static";
        document.getElementById("layout-content-container").style.marginLeft = "0px";
        setInterval(
            function(){ location.reload() },
            500
        );
    }
}
</script>
</body>
</html>
