<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="BioAIm, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="icon" href="./images/BioAIm_banner.jpg">
<link rel="stylesheet" href="main.css" type="text/css" />
<link rel="stylesheet" href="font-awesome/css/font-awesome.min.css">
<!--- <title></title> --->
<title>BioAIm</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<div id="layout-content"> <!-- nomenu  -->
<div id="banner-container">
<img src="./images/banner_main.png" alt="logo pic" />
<div id="menu-overlay">
<a href="index.html">About</a>
<a href="projects.html">Projects</a>
<a href="team.html">Team</a>
<a href="teaching.html">Teaching</a>
<a href="vacancies.html">Vacancies</a>
<a href="publications_All.html">Publications</a>
</div>
</div>
<h1>Projects - Selected Publications</h1>
<h2>Human Motion Analysis and Privacy Preservation </h2>
<div id="text-img-container"><div id="img-container">
<img src="./images/projects/2024_HPE_KnowledgeDistil_Kaushik.png" alt="" width="240px" /></div>
<div id="text-container"><h2>Efficient Human Pose Estimation</h2>
<h3>Knowledge Distillation with Global Filters for Efficient Human Pose Estimation</h3>
<p>K.B. Sivangi and F. Deligianni
BMVC 2024
<a href="https://eprints.gla.ac.uk/330515/" target=&ldquo;blank&rdquo;>pdf</a></p>
<p>By distilling knowledge from the teacher model, the student network learns to predict keypoints with high accuracy while maintaining lower computational complexity. 
This approach significantly advances the field by balancing efficiency and accuracy.  
We specifically employ Global Filter Layers, which operate in the frequency domain, to reduce the processing overhead associated with traditional attention mechanisms.
Our method was evaluated using both static and dynamic filter weighting strategies, demonstrating that the Global Filter Layers not only improve speed but also maintain a competitive level of accuracy compared to traditional attention-based models. 
<a href="./publications/HPE_KD.html" target=&ldquo;blank&rdquo;>&hellip;read more</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/projects/2024_radarImg_IZ.jpg" alt="" width="280px" /></div>
<div id="text-container"><h2>Privacy-Preserved Human Activity Recognition</h2>
<h3>Privacy Preservation in Radar-based Human Activity Recognition </h3>
<p>I. Zakariyya, L. Tran, K.B. Sivangi, F. Deligianni, <a href="submitted" target=&ldquo;blank&rdquo;>submitted</a></p>
<p>Privacy Preservation in Radar-based Human Activity Recognition </p>
</div></div>
<h2>Medical Image Analysis</h2>
<div id="text-img-container"><div id="img-container">
<img src="./images/projects/2024_Registration_SSL_QL.jpg" alt="" width="250px" /></div>
<div id="text-container"><h2>Semi-Supervised Medical Image Segmentation</h2>
<h3>Learning Semi-Supervised Medical Image Segmentation from Spatial Registration</h3>
<p>Q. Liu, P. Henderson, X. Gu, H. Dai, <a href="https://arxiv.org/abs/2409.10422" target=&ldquo;blank&rdquo;>submitted</a></p>
<p>We are the first to propose a registration-guided method for semi-supervised medical image segmentation, by integrating registration with a contrastive
cross-teaching framework. Furthermore, we introduce a novel registration supervision loss that enhances cross-teaching, by providing additional and
informative registered pseudo-labels early in training, automatically selecting the best registered volumes.<a href="Read" target=&ldquo;blank&rdquo;>more</a></p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/projects/BraTS2019_certaintyGuided.jpg" alt="" width="280px" /></div>
<div id="text-container"><h2>Semi-Supervised Medical Image Segmentation</h2>
<h3>Certainty-Guided Cross Contrastive Learning for Semi-Supervised Medical Image Segmentation</h3>
<p>Q. Liu, X. Gu, P. Henderson, BMVC 2023.
<a href="https://arxiv.org/abs/2306.14293" target=&ldquo;blank&rdquo;>BMVC2023</a>, <a href="https://www.techrxiv.org/users/815474/articles/1216359-certainty-guided-cross-contrastive-learning-for-semi-supervised-medical-image-segmentation" target=&ldquo;blank&rdquo;>Extended Version</a></p>
<p>We develop a novel Multi-Scale Cross Supervised Contrastive Learning (MCSC) framework, to segment structures in medical images. We jointly train CNN and Transformer models, regularising their features to be semantically consistent across different scales. 
To tackle class imbalance, we take into account the prevalence of each class to guide contrastive learning and ensure that features adequately capture infrequent classes.</p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/projects/2023_ICASSP_segmentation_results.jpg" alt="" width="280px" /></div>
<div id="text-container"><h2>Fully Supervised Medical Image Segmentation</h2>
<h3>Optimizing Vision Transformers for Medical Image Segmentation</h3>
<p>Q. Liu, C. Kaul, J. Wang, C. Anagnostopoulos, R. Murray-Smith, F. Deligianni, IEEE International Conference on Acoustics, Speech, and Signal Processing, 2023.
<a href="https://ieeexplore.ieee.org/document/10096379" target=&ldquo;blank&rdquo;>paper</a></p>
<p>We design of a compact and accurate Transformer network for Medical Image Semantic Segmentation, which introduces convolutions in a multi-stage design for hierarchically enhancing spatial and local modeling ability of Transformers. This is mainly achieved by our well-designed Convolutional Swin Transformer (CST) block which merges convolutions with Multi-Head Self-Attention and Feed-Forward Networks for providing inherent localized spatial context and inductive biases.</p>
</div></div>
<h2>Analysis of Neurophysiological Signals</h2>
<div id="text-img-container"><div id="img-container">
<img src="./images/projects/2024_musicGait_ACII_small.jpg" alt="" width="280px" /></div>
<div id="text-container"><h2>Computational Interfaces for Personalised Music-Therapy</h2>
<h3>Fusion of Spatial and Riemannian Features to Enhance Detection of Gait Adaptation Mental States During Rhythmic Auditory Stimulation</h3>
<p>N. Lai-Tan, M. Philiastides, F. Deligianni, 
International Conference on Affective Computing and Intelligent Interaction (ACII 2024), Best Student Paper Runner-up Award, 2024.
<a href="https://eprints.gla.ac.uk/328351/" target=&ldquo;blank&rdquo;>paper</a></p>
<p>Fusion of Spatial and Riemannian Features to Enhance Detection of Gait Adaptation Mental States During Rhythmic Auditory Stimulation&nbsp;&nbsp;&nbsp;</p>
</div></div>
<div id="text-img-container"><div id="img-container">
<img src="./images/projects/2024_ECG_ISBI_MA.jpg" alt="" width="280px" /></div>
<div id="text-container"><h2>12-Lead ECG Classification in Congenital Heart Disease</h2>
<h3>Riemannian Prediction of Anatomical Diagnoses in Congenital Heart Disease based on 12-lead ECG's</h3>
<p>M. Alkan, G. Veldtman, F. Deligianni, IEEE International Symposium on Biomedical Imaging (IEEE ISBI), 2024 
<a href="https://arxiv.org/abs/2312.09437" target=&ldquo;blank&rdquo;>arxiv</a>, <a href="https://ieeexplore.ieee.org/document/10635164" target=&ldquo;blank&rdquo;>paper</a>, <a href="https://github.com/alkanmuhammet/ISBI" target=&ldquo;blank&rdquo;>code</a></p>
<p>Here, we exploit the Riemannian geometry of the spatial covariance structure of the ECG signal to improve classification in extremely heterogeneous and small datasets.</p>
</div></div>
</div> <!-- <div id="layout-content"> -->
<div id="footer-container">
<div id="footer">
<div id="footer-text">
Last edited  on September 23<sup>rd</sup> 2024  06:46PM (Time Zone: GMT Summer Time). </br>
Powered by <a href="https://github.com/szl2/jemdoc-new-design" target="blank">jemdoc + new design</a>.
</div> <!-- <div id="footer-text"> -->
</div> <!-- <div id="footer"> -->
</div> <!-- <div id="footer-container"> -->
<div> <!-- nomenulastbit to counteract  <div id="layout">  -->
</div> <!--- <div id="layout"> --->
</div> <!--- <div id="main-container"> --->
<script>
function openNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "280px";
        document.getElementById("layout-content-container").style.marginLeft = "280.8px";
        document.getElementById("layout-content-container").style.position = "fixed";
    }
}
function closeNav() {
    if (window.innerWidth <= 1200) {
        document.getElementById("layout-menu").style.width = "0";
        document.getElementById("layout-content-container").style.position = "static";
        document.getElementById("layout-content-container").style.marginLeft = "0px";
        setInterval(
            function(){ location.reload() },
            500
        );
    }
}
</script>
</body>
</html>
